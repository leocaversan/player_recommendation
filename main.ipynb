{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import all lib i will need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, translate, concat_ws, udf\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import PCA\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "from scipy.spatial.distance import euclidean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Spark Session object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .appName('Iniciando com Spark') \\\n",
    "    .config('spark.ui.port', '4050') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(\n",
    "    file_location:str,\n",
    "    infer_schema = \"true\",\n",
    "    first_row_is_header = \"true\",\n",
    "    delimiter = \"|\",\n",
    "    file_type = 'csv'\n",
    "    ):\n",
    "    \n",
    "    df_spark = spark.read.format(file_type) \\\n",
    "    .option('inferSchema', infer_schema) \\\n",
    "    .option('header', first_row_is_header) \\\n",
    "    .option('sep', delimiter) \\\n",
    "    .load(file_location)\n",
    "\n",
    "    return df_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alter_type_column(\n",
    "        df,\n",
    "        column_name:str,\n",
    "        new_type:str,\n",
    "    ):\n",
    "    \n",
    "    df_ajusted = df.withColumn(column_name, df[column_name].cast(new_type))\n",
    "        \n",
    "    return df_ajusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_string_rows(\n",
    "        df,\n",
    "        cols:[],\n",
    "        type_of_col:str\n",
    "):\n",
    "    for i in cols:\n",
    "        df = df.withColumn(\"isNumber\", col(str(i)).cast(type_of_col).isNotNull()).filter(col(\"isNumber\") == True)\n",
    "        df = df.drop(\"isNumber\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This functions bellow is responsible for create the cluster and register the cluster in the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_clusters(\n",
    "    df_data_sp,\n",
    "    columns_not_object:[],\n",
    "    k_pca=2,\n",
    "    SEED=1224\n",
    "    ):\n",
    "\n",
    "    pca_pipeline = Pipeline(\n",
    "        stages = [\n",
    "            VectorAssembler(inputCols=columns_not_object,outputCol='features'),\n",
    "            StandardScaler(inputCol='features', outputCol='features_scaled'),\n",
    "            PCA(k=k_pca, inputCol='features_scaled', outputCol='pca_features')\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    model_pca_pipeline = pca_pipeline.fit(df_data_sp)\n",
    "    projection = model_pca_pipeline.transform(df_data_sp)\n",
    "\n",
    "    kmeans = KMeans(k=20, featuresCol='pca_features',\\\n",
    "        predictionCol='cluster_pca', seed=SEED)\n",
    "    model_kmeans = kmeans.fit(projection)\n",
    "    projection_kmeans = model_kmeans.transform(projection)\n",
    "\n",
    "    projection_kmeans = projection_kmeans.withColumn('x', vector_to_array('pca_features')[0])\\\n",
    "        .withColumn('y', vector_to_array('pca_features')[1])\n",
    "    \n",
    "    return projection_kmeans\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This functions is responsible for creating the df of recommendations considered by the distance between two points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def created_recommendation (\n",
    "    projection_kmeans,\n",
    "    selected_music = 'Sergei Rachmaninoff| James Levine| Berliner Philharmoniker_Piano Concerto No. 3 in D Minor, Op. 30: III. Finale. Alla breve',\n",
    "    columns_of_interesse = ['pca_features', 'cluster_pca',\\\n",
    "                        'artists','name', 'year', 'name_music_artists']\n",
    "    ):\n",
    "    \n",
    "    def calculate_distance(value):\n",
    "        return euclidean(music_components, value)\n",
    "\n",
    "    selected_colections = projection_kmeans.filter(projection_kmeans.name_music_artists == selected_music).select(columns_of_interesse).take(1)[0]\n",
    "\n",
    "    recommended_musics =  projection_kmeans.where(projection_kmeans.cluster_pca == selected_colections[1])\n",
    "\n",
    "    music_components = recommended_musics.filter(recommended_musics\\\n",
    "        .name_music_artists == selected_colections[5])\\\n",
    "        .dropDuplicates(['name_music_artists'])\\\n",
    "        .select('pca_features').collect()[0][0]\n",
    "\n",
    "    udf_calculate_distance = udf(\n",
    "        calculate_distance, \n",
    "        FloatType()\n",
    "        )\n",
    "\n",
    "    recommended_musics_dist = recommended_musics.withColumn(\n",
    "        'Dist', \n",
    "        udf_calculate_distance('pca_features')\n",
    "        )\n",
    "    recommendation = spark.createDataFrame(\n",
    "        recommended_musics_dist.sort('Dist').take(11)\n",
    "        ).select(['name','artists','id', 'Dist'])\n",
    "    recommendation = recommendation.where(recommendation.Dist>0)\n",
    "    \n",
    "    return recommendation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = read_file('./data/data.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## this block of code should clean the database and remove the \"broken of rows.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "float_columns = ['valence','acousticness', 'danceability', \\\n",
    "                'instrumentalness', 'liveness', 'loudness',\\\n",
    "                'speechiness', 'tempo']\n",
    "int_columns = ['duration_ms', 'energy', 'key', 'mode', \\\n",
    "                'popularity', 'release_date', 'explicit']\n",
    "\n",
    "for i in float_columns:\n",
    "    df_data = alter_type_column(\n",
    "        df_data,\n",
    "        column_name=i,\n",
    "        new_type='float'\n",
    "    )\n",
    "for i in int_columns:\n",
    "    df_data = alter_type_column(\n",
    "        df_data,\n",
    "        column_name=i,\n",
    "        new_type='int'\n",
    "    )\n",
    "    \n",
    "df_data = df_data.withColumn(\"artists\", translate(\"artists\", \"[]'\", \"\"))\n",
    "df_data = df_data.withColumn(\"artists\", translate('artists', '\"', ''))\n",
    "df_data = df_data.withColumn(\"artists\", translate(\"artists\", \",\", \"|\"))\n",
    "\n",
    "df_data = df_data.withColumn('name_music_artists', (concat_ws('_',df_data.artists, df_data.name)))\n",
    "\n",
    "df_columns = df_data.columns\n",
    "df_data = df_data[df_columns]\n",
    "\n",
    "df_data = df_data.na.drop(subset=['release_date'])\n",
    "\n",
    "columns_not_object = df_data.columns\n",
    "columns_not_object.remove('artists')\n",
    "columns_not_object.remove('id')\n",
    "columns_not_object.remove('name')\n",
    "columns_not_object.remove('name_music_artists')\n",
    "columns_not_object.remove('explicit')\n",
    "\n",
    "df_data = df_data.filter(\n",
    "    (df_data.speechiness<1) \n",
    "    & \n",
    "    (df_data.energy < 1)\n",
    "    &\n",
    "    (df_data.explicit < 1)\n",
    "    )\n",
    "\n",
    "df_data = remove_string_rows(\n",
    "        df=df_data,\n",
    "        cols=float_columns,\n",
    "        type_of_col= \"float\"\n",
    ")\n",
    "df_data = remove_string_rows(\n",
    "        df=df_data,\n",
    "        cols=int_columns,\n",
    "        type_of_col= \"int\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 567:=================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+------------------+-------------------+--------------------+-------------------+------------------+------+--------+--------------------+-------------------+------------------+-------------------+-------------------+------------------+--------------------+------------------+------------------+-------------------+------------------+--------------------+\n",
      "|summary|            valence|              year|       acousticness|             artists|       danceability|       duration_ms|energy|explicit|                  id|   instrumentalness|               key|           liveness|           loudness|              mode|                name|        popularity|      release_date|        speechiness|             tempo|  name_music_artists|\n",
      "+-------+-------------------+------------------+-------------------+--------------------+-------------------+------------------+------+--------+--------------------+-------------------+------------------+-------------------+-------------------+------------------+--------------------+------------------+------------------+-------------------+------------------+--------------------+\n",
      "|  count|              46563|             46563|              46563|               46563|              46563|             46563| 46563|   46563|               46563|              46563|             46563|              46563|              46563|             46563|               46563|             46563|             46563|              46563|             46563|               46563|\n",
      "|   mean| 0.4993512319487003|1963.6090243326246| 0.6249156824037777|               381.0|0.49960213258305336|238284.49653158087|   0.0|     0.0|                null|0.23155891259684366| 5.168889461589674| 0.2037281275491859|-13.687102588446002|0.7287545905547324|            Infinity|22.092841956059534|1963.6090243326246|0.09358110094472445|114.37653083060663|                null|\n",
      "| stddev|0.27490602623300964| 21.42036299152901|0.35652682070629094|   384.6676487566897|0.17680390806228163| 143701.9237990212|   0.0|     0.0|                null| 0.3562177414684827|3.4869711331456656|0.17149952273173463|  5.997749285135816|0.4446072228790148|                 NaN|18.658244784925234| 21.42036299152901|0.17755159091595396|30.723306733188817|                null|\n",
      "|    min|                0.0|              1921|                0.0|101 Strings Orche...|                0.0|              5108|     0|       0|000mGrJNc2GAgQdME...|                0.0|                 0|                0.0|              -60.0|                 0|\"\"\"Eungenio\"\" Sal...|                 0|              1921|                0.0|               0.0|101 Strings Orche...|\n",
      "|    25%|              0.264|              1948|              0.294|               112.0|              0.369|            162187|     0|       0|                null|            2.55E-6|                 2|             0.0991|            -17.214|                 0|               214.0|                 2|              1948|             0.0349|            90.716|                null|\n",
      "|    50%|              0.505|              1962|              0.763|               112.0|              0.508|            202453|     0|       0|                null|            0.00132|                 5|              0.136|            -12.891|                 1|              1906.0|                22|              1962|             0.0428|           111.343|                null|\n",
      "|    75%|               0.73|              1980|              0.951|               707.0|              0.634|            273227|     0|       0|                null|              0.484|                 8|              0.254|             -9.354|                 1|              1976.0|                36|              1980|             0.0618|           133.124|                null|\n",
      "|    max|                1.0|              2017|              0.996|              陳蘭麗|              0.977|           3816373|     0|       0|7zzbfi8fvHe6hm342...|              0.996|                11|              0.999|              0.674|                 1|              黄昏れ|                82|              2017|              0.969|           243.372|     陳蘭麗_你懂不懂|\n",
      "+-------+-------------------+------------------+-------------------+--------------------+-------------------+------------------+------+--------+--------------------+-------------------+------------------+-------------------+-------------------+------------------+--------------------+------------------+------------------+-------------------+------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_data.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "projection_kmeans = project_clusters(\n",
    "    df_data_sp=df_data,\n",
    "    columns_not_object=columns_not_object\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+--------------------+-------------------+\n",
      "|                name|            artists|                  id|               Dist|\n",
      "+--------------------+-------------------+--------------------+-------------------+\n",
      "|       Mannish Woman|Reverend J.M. Gates|3FeZTKBjxCGzIhmxd...|0.05701521784067154|\n",
      "|Chapter 1.13 - Dz...|Zofia Dromlewiczowa|78hZxBr4FDd8Lq9P0...|0.10150286555290222|\n",
      "|Capítulo 1.1 - la...|     H.P. Lovecraft|08i6R3zRuUMSiH0Xg...|0.10356761515140533|\n",
      "|Chapter 1.2 - Dzi...|Zofia Dromlewiczowa|5BImx4bzd8vZadkJy...|0.12527886033058167|\n",
      "|Chapter 2.17 - Dz...|Zofia Dromlewiczowa|1sT888U3vZ9tC0RpD...|0.13612665235996246|\n",
      "|The Grey Goose (1...|         Lead Belly|00MzW0XvVaoEsgEtO...|0.13680696487426758|\n",
      "|Chapter 1.1 - Dzi...|Zofia Dromlewiczowa|5u2E1EauR9jEG5vU2...|0.17054855823516846|\n",
      "|Capítulo 15.2 - l...|     H.P. Lovecraft|5wQafB5JcmRqii5Gm...|0.17213831841945648|\n",
      "|  The Pasture Mowing|       Robert Frost|3tAZj800raqqhIsN7...|0.17814892530441284|\n",
      "|Capítulo 6.5 & Ca...|     H.P. Lovecraft|1CtO5xV1VnevzNKTc...|0.18563851714134216|\n",
      "+--------------------+-------------------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recommendation = created_recommendation(\n",
    "    projection_kmeans,\n",
    "    selected_music='Dennis Day_Clancy Lowered the Boom'\n",
    "    )\n",
    "recommendation.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
